{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:30:18.109327Z",
     "start_time": "2020-03-19T18:30:18.103344Z"
    }
   },
   "source": [
    "# Miniejercicio 1\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "Nombre: ----\n",
    "\n",
    "Fecha de Entrega: Lunes 6 de Abril\n",
    "\n",
    "\n",
    "## Objetivos del ejercicio\n",
    "\n",
    "Este ejericio cuenta con varios objetivos principales: \n",
    "\n",
    "- Evaluar los contenidos de las primeras semanas de clases. En particular Information Retrieval (IR) y Vector Space Models. \n",
    "\n",
    "- Introducirlos a la programación en python enfocada en NLP.\n",
    "\n",
    "- Implementar un modelo básico de IR: Frequency-Inverse Document Frequency (TF-IDF).\n",
    "\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "- El ejercicio consiste en desarrolar 2 partes:\n",
    "\n",
    "    - La primera, trata acerca de responder preguntas relativas a los contenidos vistos en los videos y slides de las clases. \n",
    "    - La segunda, consiste en implementar el modelo Term TF-IFD utilizando solo las herramientas de python y numpy. Está PROHIBIDO usar cualquier paquete que implemente dicho modelo (NLTK, spacy, scikit, etc...).\n",
    "\n",
    "- Los ejercicios pueden ser resultos en solitario o en parejas. Máximo 2 personas...\n",
    "\n",
    "- La entrega debe ser por ucursos a mas tardar el día estipulado arriba. No se aceptan atrasos.\n",
    "\n",
    "- En el horario de auxiliar se abriran horarios de consulta en donde podrán preguntar acerca del ejercicio y en general, de todo el curso. \n",
    "\n",
    "- Está demás decir que no se admiten copias, ni de código, ni de respuestas escritas. \n",
    "\n",
    "- Cada punto equivale a 0.5 décimas de la nota\n",
    "\n",
    "\n",
    "## Referencias\n",
    " \n",
    "Slides:\n",
    "    \n",
    "- [Introducción al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
    "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
    "\n",
    "Videos: \n",
    "\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1. \n",
    "\n",
    "La siguientes celdas contendrán preguntas acerca del contenido visto en clases y en el material del curso. La idea es contestar cada pregunta en su celda correspondiente. Las respuestas deben ser breves: máximo 3 lineas (salvo para la p3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P1) Son Natural Language Processing y Computational Linguistics lo mismo? (1 Punto)**\n",
    "\n",
    "    Respuesta: \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P2) Por qué estudiar el lenguaje humano es difícil? (1 Punto)**\n",
    "\n",
    "    Respuesta: \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:45:25.544502Z",
     "start_time": "2020-03-19T18:45:25.537548Z"
    }
   },
   "source": [
    "\n",
    "**P3) Para el siguiente corpus:**\n",
    "\n",
    "    d1) I like human languages\n",
    "\n",
    "    d2) I like programming languages\n",
    "\n",
    "    d3) Spanish is my favorite language\n",
    "\n",
    "\n",
    "**Extraiga el vocabulario:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Solamente usando tokenization (1.5 puntos)**\n",
    "\n",
    "Respuesta: \n",
    "\n",
    "        Vocabulario: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Usando stemming (proponga sus propias reglas de stemming) y borrado de stopwords (indique cuales son sus stopwords) (1.5 puntos)**\n",
    "\n",
    "Respuesta: \n",
    "\n",
    "        Stopwords: ...\n",
    "        \n",
    "        Reglas de Stemming: ...\n",
    "        \n",
    "        Vocabulario: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:46:24.015666Z",
     "start_time": "2020-03-19T18:46:24.010706Z"
    }
   },
   "source": [
    "**P4) Conceptualmente cuál es la diferencia entre usar machine learning clásico (empirismo) y deep learning para un problema de NLP (Puede usar el análisis de sentimientos como ejemplo) (1 punto)**\n",
    "\n",
    "    Respuesta: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:47:04.360754Z",
     "start_time": "2020-03-19T18:47:04.357763Z"
    }
   },
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:57:05.868104Z",
     "start_time": "2020-03-19T18:57:05.863117Z"
    }
   },
   "source": [
    "Impementar TF-IDF. \n",
    "\n",
    "Esta parte, cada celda representa una función distinta por implementar. Se usará pandas para representar las matrices y arreglos que vayamos calculando. Siguiente a cada celda con una función por implementar habrá un ejemplo de como debería ser el output que tienen que lograr. No vale hardcodeo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset, cada string representa un documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T18:41:30.172447Z",
     "start_time": "2020-03-20T18:41:30.167460Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    't4 t3 t1 t4', 't5 t4 t2 t3 t5', 't2 t1 t4 t4', 't2 t3 t3 t1 t4',\n",
    "    't1, t4, t2, t2', 't2, t3, t2, t3 ,t2 ,t3'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtener vocabulario (1 punto)** \n",
    "\n",
    "Implementar la función `get_vocab(dataset)` que recibe el dataset y retorna un arreglo con cada palabra que aparece en el dataset. (sin duplicar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:27:29.478377Z",
     "start_time": "2020-03-20T15:27:29.449112Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:27:26.288915Z",
     "start_time": "2020-03-20T15:27:26.262110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t4', 't3', 't1', 't5', 't2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(dataset)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular Bag of Words (bow) (2 puntos)**\n",
    "\n",
    "implementar la función `calc_bow(dataset, vocab)` que toma el dataset y el vocabulario calculado en la parte anterior y retorna un pandas DataFrame en donde las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabra los documento. En otras palabras, cada fila representa el bow de un determinado documento\n",
    "\n",
    "el bow de cada documento.\n",
    "\n",
    "Recordatorio - Bag of Words: Cuenta las apariciones de cada palabra en cada uno de los documentos. Por ejemplo:\n",
    "\n",
    "Por ejemplo, para los documentos: \n",
    "\n",
    "```\n",
    "d_0 = 'El perro ladra'\n",
    "d_1 = 'El perro come'\n",
    "\n",
    "```\n",
    "\n",
    "Deberíamos retornar:\n",
    "\n",
    "|   | el | perro | ladra | come |\n",
    "|---|----|-------|------|-------|\n",
    "| 0 | 1  | 1     | 1    | 0     |\n",
    "| 1 | 1  | 1     | 0    | 1     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:11:42.127863Z",
     "start_time": "2020-03-20T15:11:42.112246Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bow(dataset, vocab):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:11:42.883125Z",
     "start_time": "2020-03-20T15:11:42.867556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t3</th>\n",
       "      <th>t1</th>\n",
       "      <th>t5</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t4  t3  t1  t5  t2\n",
       "0   2   1   1   0   0\n",
       "1   1   1   0   2   1\n",
       "2   2   0   1   0   1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow = calc_bow(dataset, vocab)\n",
    "dataset_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T14:27:01.721767Z",
     "start_time": "2020-03-20T14:27:01.716781Z"
    }
   },
   "source": [
    "**Calcular TF (1 punto)**\n",
    "\n",
    "En esta sección debemos usar el dataframe calcular la matriz de TF normalizada por el máximo $\\text{ntf}_{i,j}$. Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca mas veces ese vector. \n",
    "\n",
    "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:11:45.959270Z",
     "start_time": "2020-03-20T15:11:45.943648Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf(dataset_bow):\n",
    "    pass\n",
    "\n",
    "\n",
    "tf = calc_tf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:11:52.166499Z",
     "start_time": "2020-03-20T15:11:52.135792Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t3</th>\n",
       "      <th>t1</th>\n",
       "      <th>t5</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t4   t3   t1   t5   t2\n",
       "0  1.0  0.5  0.5  0.0  0.0\n",
       "1  0.5  0.5  0.0  1.0  0.5\n",
       "2  1.0  0.0  0.5  0.0  0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular IDF (1 punto)**\n",
    "\n",
    "\n",
    "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
    "\n",
    "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ número de documentos y $n_i = $ Número de documentos que contienen la palabra $t_i$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:15:56.768610Z",
     "start_time": "2020-03-20T15:15:56.752957Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_idf(dataset_bow):\n",
    "    pass\n",
    "\n",
    "\n",
    "idf = calc_idf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:19:05.851423Z",
     "start_time": "2020-03-20T15:19:05.820175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t4': 0.0,\n",
       " 't3': 0.17609125905568124,\n",
       " 't1': 0.17609125905568124,\n",
       " 't5': 0.47712125471966244,\n",
       " 't2': 0.17609125905568124}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular TF-IDF (1 punto)**\n",
    "\n",
    "Por último, implementar `calc_tf_idf(tf, idf)`. Esta debe cumplir que \n",
    "\n",
    "$$tf{-}idf = tf_{i,j} * idf_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:04:00.204455Z",
     "start_time": "2020-03-20T15:04:00.188809Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf_idf(tf, idf):\n",
    "    pass\n",
    "\n",
    "\n",
    "tf_idf = calc_tf_idf(tf, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:20:15.830094Z",
     "start_time": "2020-03-20T15:20:15.814468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t3</th>\n",
       "      <th>t1</th>\n",
       "      <th>t5</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132068</td>\n",
       "      <td>0.132068</td>\n",
       "      <td>0.238561</td>\n",
       "      <td>0.088046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132068</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.132068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.132068</td>\n",
       "      <td>0.238561</td>\n",
       "      <td>0.132068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t4        t3        t1        t5        t2\n",
       "0  0.0  0.132068  0.132068  0.238561  0.088046\n",
       "1  0.0  0.132068  0.088046  0.477121  0.132068\n",
       "2  0.0  0.088046  0.132068  0.238561  0.132068"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus: Hacer una función para realizar una Query (2 puntos extra)**\n",
    "\n",
    "`query(sentence, tf_idf)` función debe retornar un ranking con los documentos mas relevantes para la palabra consultada. \n",
    "\n",
    "Sugerencias:\n",
    "\n",
    "- Primero, transformar la oración al modelo tf_idf (ojo que solo funciona cuando todas las palabras de la oración existen en el modelo que acabas de crear).\n",
    "- Luego, usar similitud coseno para comparar los documentos ya precalculados y la oración que acabas de consultar.\n",
    "- A partir de eso, crear un ranking con los documentos mas similares.\n",
    "\n",
    "Deben reportar por lo menos 2 ejemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T15:20:17.904592Z",
     "start_time": "2020-03-20T15:20:17.888971Z"
    }
   },
   "outputs": [],
   "source": [
    "def query(sentence, tf_idf):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usar dato reales (Opcional, sin puntaje)**\n",
    "\n",
    "Adicionalmente, existe la alternativa de utilizar un dataset de noticias:\n",
    "\n",
    "El modelo que creaste anteriormente no debería dejar de funcionar si cargas este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T18:38:39.068569Z",
     "start_time": "2020-03-20T18:38:29.689892Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "BASE_URL = 'https://github.com/dccuchile/CC6205/releases/download/Data/{}.json'\n",
    "\n",
    "dataset = pd.concat([\n",
    "    pd.read_json(BASE_URL.format('biobio_nacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_opinion')),\n",
    "    pd.read_json(BASE_URL.format('biobio_internacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_sociedad')),\n",
    "    pd.read_json(BASE_URL.format('biobio_economia'))\n",
    "])\n",
    "\n",
    "\n",
    "def clean_doc(doc):\n",
    "    return ' '.join(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda x: x != '',\n",
    "                re.sub(\"\\?|\\¿|\\:|\\!|\\¡|\\(|\\)|\\t|\\n|“|”|\\\"|\\'|\\s\\s+|\\.|\\,|\\;\",\n",
    "                       \" \", doc.lower()).split(' '))))\n",
    "\n",
    "\n",
    "dataset = list(\n",
    "    map(lambda x: clean_doc(x[0] + '.' + x[1]), dataset[['title',\n",
    "                                                         'content']].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
