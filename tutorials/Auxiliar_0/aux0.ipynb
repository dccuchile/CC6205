{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1iISOcrM_SZ"
   },
   "source": [
    "# Markdown\n",
    "\n",
    "Esta es una celda de texto.\n",
    "\n",
    "# Esto es un titulo grandote\n",
    "\n",
    "## Esto es un titulo un poco menos grandote\n",
    "\n",
    "\n",
    "Esto es un parrafo, `esto esta en codigo`, **esto esta en negrita**, *esto esta en cursiva*\n",
    "\n",
    "Se puede insertar codigo multilinea tambien.\n",
    "```java\n",
    "public static void main(String args[]) { \n",
    "    System.out.println(\"wena\");\n",
    "} \n",
    "```\n",
    "\n",
    "\n",
    "Se pueden insertar lineas para separar texto\n",
    "\n",
    "---\n",
    "\n",
    "Se pueden insertar tablas!\n",
    "\n",
    "| Esto      | Es   | Una  | Tabla   | !!      |\n",
    "|-----------|------|------|---------|---------|\n",
    "| 1         | 2    | hola | chao    | un dato |\n",
    "| otro dato | pero | mira | cuantos | datos   |\n",
    "\n",
    "\n",
    "\n",
    "Se puede \"citar\" texto usando cabezas de pescado\n",
    "> Esta es una frase celebre de algun famoso\n",
    ">\n",
    "> -- Albert Einstein\n",
    "\n",
    "Tambien se puede insertar formulas de $\\LaTeX$ dentro del mismo texto: $a = \\frac{e^y\\sqrt{x+2}}{x^2}$. Se puede insertar $\\LaTeX$ en general tambien.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\it{CE}(p,q)=\\sum_{x}p(x)\\log \\bigg(\\frac{1}{q(x)}\\bigg)=- \\sum_{x}p(x)\\log q(x)\n",
    "\\end{equation}\n",
    "\n",
    "Tambien se puede escribir `html`.\n",
    "\n",
    "<strong> Esto esta en negrita usando html </strong>\n",
    "\n",
    "Aca dejo mas recursos sobre Markdown, Colab y Jupyter Notebook:\n",
    "* https://help.github.com/en/github/writing-on-github/basic-writing-and-formatting-syntax\n",
    "* https://colab.research.google.com/notebooks/intro.ipynb\n",
    "* https://jupyter.org/\n",
    "* https://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXFCSsVL3a31"
   },
   "source": [
    "# Pequeña introduccion a Numpy y Pandas\n",
    "\n",
    "Colab viene con muchas librerias preinstaldas. Dentro de las que mas vamos a usar estan Numpy y Pandas. Aca tambien dejo unas \"cheat sheets\" para ambas bibliotecas.\n",
    "* https://pandas.pydata.org/docs/\n",
    "* https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "* https://numpy.org/doc/1.18/\n",
    "* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2pIg5bq3mVf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eSRuM3bFBHQm",
    "outputId": "93da3a49-9566-4cec-d0e3-f75bccba1f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "a\n",
    "b = []\n",
    "for e in a:\n",
    "    b.append(e**2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Udj41ExxfDrE"
   },
   "source": [
    "## Numpy\n",
    "Paquete fundamental para computacion matematica.\n",
    "\n",
    "Clase principal: arraglo n-dimensional, ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "y6tLcmKuhiVx",
    "outputId": "01a4a547-a014-45a2-d0c8-3a0fdd8cf662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] \n",
      "\n",
      "[ 3  5  7  9 11 13 15 17 19] \n",
      "\n",
      "[1.         1.11111111 1.22222222 1.33333333 1.44444444 1.55555556\n",
      " 1.66666667 1.77777778 1.88888889 2.        ] \n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Como crear arreglos\n",
    "\n",
    "# A partir de otro una lista de python\n",
    "print(np.array(range(10)), \"\\n\")\n",
    "\n",
    "# Un arrelo de enteros entre un rango un paso especifico\n",
    "print(np.arange(3, 20, 2), \"\\n\")\n",
    "\n",
    "# Un arreglo con 10 numero entre 1 y 2\n",
    "print(np.linspace(1,2,10), \"\\n\")\n",
    "\n",
    "# Un arreglo de puros 0\n",
    "print(np.zeros(10), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "F1D_DOmBB83t",
    "outputId": "adeffaa8-4987-4b85-f4dd-c9a182857029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "AWflrWVbiw7b",
    "outputId": "f406b79c-5e1f-4ee3-d839-6ed6d013fcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "====================\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]\n",
      "  [30 31 32 33 34]\n",
      "  [35 36 37 38 39]]\n",
      "\n",
      " [[40 41 42 43 44]\n",
      "  [45 46 47 48 49]\n",
      "  [50 51 52 53 54]\n",
      "  [55 56 57 58 59]]]\n"
     ]
    }
   ],
   "source": [
    "# arreglos de mas dimensiones\n",
    "print(np.arange(20).reshape(4,5))\n",
    "print(\"=\" * 20)\n",
    "print(np.arange(60).reshape(3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsxRvWDaiL9_"
   },
   "outputs": [],
   "source": [
    "# Operaciones sobre arreglos\n",
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MAn6vVZ0-M7a",
    "outputId": "05c0f747-cca1-4e89-d7b2-b0e1dc6fcea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XVewYvUz-Stw",
    "outputId": "09114666-8d07-491a-aade-9ea32fb6d0d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.        , 1.41421356, 1.73205081, 2.        ,\n",
       "       2.23606798, 2.44948974, 2.64575131, 2.82842712, 3.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "jCn5Q7Pa-VIx",
    "outputId": "3fa0627b-67a9-4444-91e2-c045e35bc7ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 3.14159265e+00, 9.86960440e+00, 3.10062767e+01,\n",
       "       9.74090910e+01, 3.06019685e+02, 9.61389194e+02, 3.02029323e+03,\n",
       "       9.48853102e+03, 2.98090993e+04])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi**a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M30GVjFp-Xi5",
    "outputId": "ae99b2ce-458b-46f7-c695-bf12885d6fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  9, 11, 13, 15, 17, 19, 21, 23])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(5,15)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yu5JJELh-bdS",
    "outputId": "17396396-1b8d-46dc-bff9-41ed4918fa98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   6,  14,  24,  36,  50,  66,  84, 104, 126])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uQawYtDI-daL",
    "outputId": "3c3c0bd3-c101-406a-f2cc-13b10d20fe8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKe3EPPKBXX6",
    "outputId": "184c6d2e-490c-4ae5-9110-5cfb1afc9ef9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 22, 38])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3,4)\n",
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "canRRMhyHMC_",
    "outputId": "391f1dbd-b4fb-4f3c-beb5-e356c5e14d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "a = np.arange(12).reshape(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4tvQzA27HpOj",
    "outputId": "7b2d67bb-1061-419c-feda-6e518e8487e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BI-Rr448HUZ-",
    "outputId": "da8291bd-36b4-459a-d3b7-c45120407704"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CdwHTedQHX1m",
    "outputId": "b203eab2-dd6e-4709-c1c8-e294546337ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pq31XS5DHaDd",
    "outputId": "7048f9eb-b620-4652-b91e-85c41d78778a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2, 0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gai7XWPNE9yM",
    "outputId": "6b741364-05b6-4d7b-ec19-4c203175ec52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ox0v96zvF1p0",
    "outputId": "393d7425-34e0-48d4-b2a4-fec2071962d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "fQdS-nGvGAUL",
    "outputId": "44055398-96ec-45ae-ee83-f18dee2024e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(10*6).reshape(6,10)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "6afGxftPGfjZ",
    "outputId": "9c2241d1-711a-47cb-dcd3-1996e05d29f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "       [10, 12, 14, 16, 18, 20, 22, 24, 26, 28],\n",
       "       [20, 22, 24, 26, 28, 30, 32, 34, 36, 38],\n",
       "       [30, 32, 34, 36, 38, 40, 42, 44, 46, 48],\n",
       "       [40, 42, 44, 46, 48, 50, 52, 54, 56, 58],\n",
       "       [50, 52, 54, 56, 58, 60, 62, 64, 66, 68]])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LaLOoZJ3rUt"
   },
   "source": [
    "## Pandas\n",
    "Una herramienta para hacer analisis y manipulacion de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "1RfYSH7R7HCM",
    "outputId": "671dc70d-36ff-42bc-dd41-ecedd877ba19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(200, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_hour</th>\n",
       "      <th>author</th>\n",
       "      <th>author_link</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>embedded_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>10:50</td>\n",
       "      <td>Gonzalo Cifuentes</td>\n",
       "      <td>/lista/autores/gcifuentes</td>\n",
       "      <td>¿Lavar la ropa con luz?: invento de chilenos e...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Alumnos de Ingeniería de la Universidad Cató...</td>\n",
       "      <td>[#Chile, #Ingeniería UC, #LightWash, #Luz, #Se...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>07:51</td>\n",
       "      <td>Felipe Delgado</td>\n",
       "      <td>/lista/autores/fdelgado</td>\n",
       "      <td>Alrededor de 40 mil hogares de Puente Alto, Pi...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Región Metropolitana</td>\n",
       "      <td>Alrededor de 40 mil hogares de las comunas d...</td>\n",
       "      <td>[#Pirque, #Puente Alto, #Región Metropolitana,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:14</td>\n",
       "      <td>Nicolás Parra</td>\n",
       "      <td>/lista/autores/nparra</td>\n",
       "      <td>Habla director de Compin Bío Bío que se autoap...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Región del Bío Bío</td>\n",
       "      <td>Quien fuera el director de la Compin Bío Bío...</td>\n",
       "      <td>[#Compin, #Concepción, #Licencia, #Region del ...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:19</td>\n",
       "      <td>Catalina Díaz</td>\n",
       "      <td>/lista/autores/catalinadiaz</td>\n",
       "      <td>6 damnificados dejó incendio que destruyó una ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Región de los Ríos</td>\n",
       "      <td>Seis damnificados es el saldo de un incendio...</td>\n",
       "      <td>[#Bomberos, #Damnificados, #Daños, #Incendio, ...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:27</td>\n",
       "      <td>Catalina Díaz</td>\n",
       "      <td>/lista/autores/catalinadiaz</td>\n",
       "      <td>Con arresto domiciliario quedó menor detenido ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Región de los Lagos</td>\n",
       "      <td>Con arresto domiciliario total quedó el adol...</td>\n",
       "      <td>[#Arresto Domiciliario, #Bullying, #Calbuco, #...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_date publication_hour             author  \\\n",
       "0       05/08/2019            10:50  Gonzalo Cifuentes   \n",
       "1       05/08/2019            07:51     Felipe Delgado   \n",
       "2       05/08/2019            08:14      Nicolás Parra   \n",
       "3       05/08/2019            08:19      Catalina Díaz   \n",
       "4       05/08/2019            08:27      Catalina Díaz   \n",
       "\n",
       "                   author_link  \\\n",
       "0    /lista/autores/gcifuentes   \n",
       "1      /lista/autores/fdelgado   \n",
       "2        /lista/autores/nparra   \n",
       "3  /lista/autores/catalinadiaz   \n",
       "4  /lista/autores/catalinadiaz   \n",
       "\n",
       "                                               title  \\\n",
       "0  ¿Lavar la ropa con luz?: invento de chilenos e...   \n",
       "1  Alrededor de 40 mil hogares de Puente Alto, Pi...   \n",
       "2  Habla director de Compin Bío Bío que se autoap...   \n",
       "3  6 damnificados dejó incendio que destruyó una ...   \n",
       "4  Con arresto domiciliario quedó menor detenido ...   \n",
       "\n",
       "                                                link  category  \\\n",
       "0  https://www.biobiochile.cl/noticias/nacional/c...  Nacional   \n",
       "1  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "2  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "3  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "4  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "\n",
       "            subcategory                                            content  \\\n",
       "0              Nacional    Alumnos de Ingeniería de la Universidad Cató...   \n",
       "1  Región Metropolitana    Alrededor de 40 mil hogares de las comunas d...   \n",
       "2    Región del Bío Bío    Quien fuera el director de la Compin Bío Bío...   \n",
       "3    Región de los Ríos    Seis damnificados es el saldo de un incendio...   \n",
       "4   Región de los Lagos    Con arresto domiciliario total quedó el adol...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [#Chile, #Ingeniería UC, #LightWash, #Luz, #Se...   \n",
       "1  [#Pirque, #Puente Alto, #Región Metropolitana,...   \n",
       "2  [#Compin, #Concepción, #Licencia, #Region del ...   \n",
       "3  [#Bomberos, #Damnificados, #Daños, #Incendio, ...   \n",
       "4  [#Arresto Domiciliario, #Bullying, #Calbuco, #...   \n",
       "\n",
       "                                      embedded_links  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [https://media.biobiochile.cl/wp-content/uploa...  \n",
       "3  [https://media.biobiochile.cl/wp-content/uploa...  \n",
       "4  [https://media.biobiochile.cl/wp-content/uploa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer datos en distintos formatos usando las funciones read_*\n",
    "# El objeto principal es el DataFrame\n",
    "dataset = pd.read_json(\n",
    "    'https://github.com/dccuchile/CC6205/releases/download/Data/biobio_nacional.json'\n",
    ")\n",
    "print(type(dataset))\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "GkGqXSmfIlRu",
    "outputId": "71cefacc-7f9c-41b9-b2a5-c3e8d73f9c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      "publication_date    200 non-null object\n",
      "publication_hour    200 non-null object\n",
      "author              200 non-null object\n",
      "author_link         200 non-null object\n",
      "title               200 non-null object\n",
      "link                200 non-null object\n",
      "category            200 non-null object\n",
      "subcategory         200 non-null object\n",
      "content             200 non-null object\n",
      "tags                200 non-null object\n",
      "embedded_links      200 non-null object\n",
      "dtypes: object(11)\n",
      "memory usage: 17.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "sz-JV8zs7Jz7",
    "outputId": "3668ac6f-00de-42cb-e84b-29187fb76cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo:  <class 'pandas.core.series.Series'>\n",
      "0    Gonzalo Cifuentes\n",
      "1       Felipe Delgado\n",
      "2        Nicolás Parra\n",
      "3        Catalina Díaz\n",
      "4        Catalina Díaz\n",
      "Name: author, dtype: object\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# Obtener toda una columna\n",
    "authors = dataset[\"author\"]\n",
    "print(\"tipo: \", type(authors))\n",
    "print(authors.head())\n",
    "print(authors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qmmnL_QLOjZs",
    "outputId": "e506303f-64d4-4a0b-f13c-4c21abde9a20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_date  category\n",
       "0       05/08/2019  Nacional\n",
       "1       05/08/2019  Nacional\n",
       "2       05/08/2019  Nacional\n",
       "3       05/08/2019  Nacional\n",
       "4       05/08/2019  Nacional"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar multiples columnas\n",
    "dataset[[\"publication_date\", \"category\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "vyjRofIjO0RH",
    "outputId": "79aac8da-deb1-4d4c-ceae-e8a0d3c418b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: subcategory, dtype: bool \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_hour</th>\n",
       "      <th>author</th>\n",
       "      <th>author_link</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>embedded_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>10:50</td>\n",
       "      <td>Gonzalo Cifuentes</td>\n",
       "      <td>/lista/autores/gcifuentes</td>\n",
       "      <td>¿Lavar la ropa con luz?: invento de chilenos e...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Alumnos de Ingeniería de la Universidad Cató...</td>\n",
       "      <td>[#Chile, #Ingeniería UC, #LightWash, #Luz, #Se...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:44</td>\n",
       "      <td>Emilio Lara</td>\n",
       "      <td>/lista/autores/elara</td>\n",
       "      <td>Crisis interna del PS gatilla renuncia de 291 ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>291 militantes renunciaron al Partido Social...</td>\n",
       "      <td>[#Narcotráfico, #Partido Socialista, #PS, #Ser...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>09:50</td>\n",
       "      <td>Emilio Lara</td>\n",
       "      <td>/lista/autores/elara</td>\n",
       "      <td>Cadem: Piñera mantiene aprobación y reducción ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Los últimos resultados de la Encuesta Cadem ...</td>\n",
       "      <td>[#Cadem, #Gabinete, #Gobierno, #jornada labora...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>10:30</td>\n",
       "      <td>Emilio Lara</td>\n",
       "      <td>/lista/autores/elara</td>\n",
       "      <td>Senado podría votar esta semana extensión de g...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Esta semana, luego de un año y cuatro meses ...</td>\n",
       "      <td>[#CFT, #Educación, #Gobierno, #Gratuidad, #IP]</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>05:30</td>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>Comisión del Trabajo votará este martes petici...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>La comisión de Trabajo de la Cámara votará e...</td>\n",
       "      <td>[#Comisión del Trabajo, #Frente Amplio, #Gael ...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publication_date  ...                                     embedded_links\n",
       "0        05/08/2019  ...                                                 []\n",
       "6        05/08/2019  ...                                                 []\n",
       "11       05/08/2019  ...                                                 []\n",
       "14       05/08/2019  ...  [https://media.biobiochile.cl/wp-content/uploa...\n",
       "16       05/08/2019  ...  [https://media.biobiochile.cl/wp-content/uploa...\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar subconjunto de filas\n",
    "mask = dataset[\"subcategory\"] == \"Nacional\"\n",
    "print(mask.head(), \"\\n\")\n",
    "\n",
    "dataset[mask].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "jl2pbVeQCP2p",
    "outputId": "6a033403-a4f8-4d70-f968-99c1d1527873"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catalina Díaz</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nicolás Díaz</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>María José Villarroel</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Sandar Oporto</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Sandar Oporto</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Matías Vega</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>María José Villarroel</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Nicolás Parra</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Matías Vega</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Valentina González</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Valentina González</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Yessenia Márquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Yessenia Márquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Nicolás Díaz</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Yessenia Márquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Yessenia Márquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Valentina González</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Nicolás Parra</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Matías Vega</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author                                               link\n",
       "4            Catalina Díaz  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "22            Nicolás Díaz  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "50   María José Villarroel  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "55           Sandar Oporto  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "59           Sandar Oporto  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "63             Matías Vega  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "76   María José Villarroel  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "82           Nicolás Parra  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "89             Matías Vega  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "105     Valentina González  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "124     Valentina González  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "128         Manuel Stuardo  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "131       Yessenia Márquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "143       Yessenia Márquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "152         Manuel Stuardo  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "154           Nicolás Díaz  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "157         Manuel Stuardo  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "169       Yessenia Márquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "184       Yessenia Márquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "190     Valentina González  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "191          Nicolás Parra  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "195            Matías Vega  https://www.biobiochile.cl/noticias/nacional/r..."
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loc/iloc, loc on labels, iloc con indices\n",
    "dataset.loc[dataset[\"subcategory\"] == \"Región de los Lagos\", [\"author\", \"link\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "B69dWpTgSyUI",
    "outputId": "12b06302-7c50-43b7-8c9a-e54c4f0dc0ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_hour</th>\n",
       "      <th>author_link</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00:57</td>\n",
       "      <td>/lista/autores/ndiaz</td>\n",
       "      <td>Detienen a conductor en Coronel tras ofrecer $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21:33</td>\n",
       "      <td>/lista/autores/ndiaz</td>\n",
       "      <td>Puerto Montt implementará plan de contingencia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22:00</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>Mañalich y Comisión de Salud analizarán este l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23:16</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>En prisión preventiva queda exfuncionario de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23:49</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>Automóvil y bus del Transantiago protagonizan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publication_hour  ...                                              title\n",
       "20            00:57  ...  Detienen a conductor en Coronel tras ofrecer $...\n",
       "22            21:33  ...  Puerto Montt implementará plan de contingencia...\n",
       "24            22:00  ...  Mañalich y Comisión de Salud analizarán este l...\n",
       "26            23:16  ...  En prisión preventiva queda exfuncionario de l...\n",
       "28            23:49  ...  Automóvil y bus del Transantiago protagonizan ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[20:30:2, [1, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2h9oxU-zxhy"
   },
   "source": [
    "# NLTK\n",
    "NLTK (Natural Language Processing Kit) es una libreria de procesamiento de lenguaje natural. Ofrece utilidades como tokenizacion, lemmatization, stemming,etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BrivNfAazxPC",
    "outputId": "57b53aa8-5768-4b78-905d-542244abce33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "-OA5cQxt1Z1J",
    "outputId": "96b59bd6-be8c-4102-a2f8-29b6f24431b3"
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/spanish.pickle\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14945/1344243556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hola como están, esta es una frase en español.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spanish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/spanish.pickle\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# tokenizacion\n",
    "from nltk import word_tokenize\n",
    "s = \"Hola como están, esta es una frase en español.\"\n",
    "\n",
    "word_tokenize(s, language=\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6Gi5BRJ21gka",
    "outputId": "1d86ade8-ac4a-4d45-e5a1-973115c6ea4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "print(stemmer.stem(\"perros\"))\n",
    "stemmer.stem(\"perros\") == stemmer.stem(\"perro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "kihbH9Qf3BBd",
    "outputId": "b7f31066-069d-44b1-c06c-7d86a83fb9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hous\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14945/3410536651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"houses\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# lemmatization, no pille lemmatizer de nltk en espannol\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"houses\"))\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "print(wnl.lemmatize(\"houses\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhC7n-30cWU0"
   },
   "source": [
    "# Datos\n",
    "Aca voy a mostrar como acceder a datos desde colab.\n",
    "\n",
    "\n",
    "Una forma super simple es conectarse a su Drive y desde ahi acceder a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "33o_iAbLaX7B",
    "outputId": "7c5b45e1-b88b-4954-ad43-0d831fb85610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Esto no corre en local\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "47sC1htba_63",
    "outputId": "0468ac81-aee5-4b9d-cdbd-62047a21ab0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>idComment</th>\n",
       "      <th>creatorId</th>\n",
       "      <th>parentId</th>\n",
       "      <th>banned</th>\n",
       "      <th>authSource</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>denounces</th>\n",
       "      <th>time</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892722</td>\n",
       "      <td>4799147</td>\n",
       "      <td>160736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Muy bueno lo que vi del frstival</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516963115000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798886</td>\n",
       "      <td>7823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Improvisando y con cero libreto..ajiaj e...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1516960895000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798914</td>\n",
       "      <td>245784</td>\n",
       "      <td>4798886.0</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;@Rodrigo Cancino Sandoval[7823]&amp;nbsp;ese...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1516961099000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798783</td>\n",
       "      <td>65076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Avello es un adelantado, genial&amp;nbsp;</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516959790000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798175</td>\n",
       "      <td>11263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Su humor improvisado me pareció genial y...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1516951826000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia  idComment  creatorId  ...  denounces           time level\n",
       "0     892722    4799147     160736  ...          0  1516963115000     0\n",
       "1     892722    4798886       7823  ...          0  1516960895000     0\n",
       "2     892722    4798914     245784  ...          0  1516961099000     1\n",
       "3     892722    4798783      65076  ...          0  1516959790000     0\n",
       "4     892722    4798175      11263  ...          0  1516951826000     0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"drive/My Drive/2018_emol_comments_small.tsv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "muRycP3gctPW"
   },
   "source": [
    "Usando la habilidad de colab de ejecutar comandos de shell desde una celda de codigo, podemos descargar un dataset usando la linea de comando, ya sea con `wget` o `curl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "8L259tX3eu8v",
    "outputId": "36db9012-da19-4cd6-8dd1-24d49285bc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-26 18:53:44--  http://users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv\n",
      "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n",
      "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv [following]\n",
      "--2020-03-26 18:53:44--  https://users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv\n",
      "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11115406 (11M) [text/tab-separated-values]\n",
      "Saving to: ‘2018_emol_comments_small.tsv’\n",
      "\n",
      "2018_emol_comments_ 100%[===================>]  10.60M  4.67MB/s    in 2.3s    \n",
      "\n",
      "2020-03-26 18:53:47 (4.67 MB/s) - ‘2018_emol_comments_small.tsv’ saved [11115406/11115406]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "id": "ICb_o2_qdAtt",
    "outputId": "02e796b5-9552-4347-b505-9254820ab2ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>idComment</th>\n",
       "      <th>creatorId</th>\n",
       "      <th>parentId</th>\n",
       "      <th>banned</th>\n",
       "      <th>authSource</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>denounces</th>\n",
       "      <th>time</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892722</td>\n",
       "      <td>4799147</td>\n",
       "      <td>160736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Muy bueno lo que vi del frstival</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516963115000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798886</td>\n",
       "      <td>7823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Improvisando y con cero libreto..ajiaj e...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1516960895000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798914</td>\n",
       "      <td>245784</td>\n",
       "      <td>4798886.0</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;@Rodrigo Cancino Sandoval[7823]&amp;nbsp;ese...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1516961099000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798783</td>\n",
       "      <td>65076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Avello es un adelantado, genial&amp;nbsp;</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516959790000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798175</td>\n",
       "      <td>11263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Su humor improvisado me pareció genial y...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1516951826000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia  idComment  creatorId  ...  denounces           time level\n",
       "0     892722    4799147     160736  ...          0  1516963115000     0\n",
       "1     892722    4798886       7823  ...          0  1516960895000     0\n",
       "2     892722    4798914     245784  ...          0  1516961099000     1\n",
       "3     892722    4798783      65076  ...          0  1516959790000     0\n",
       "4     892722    4798175      11263  ...          0  1516951826000     0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"2018_emol_comments_small.tsv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "aux0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
