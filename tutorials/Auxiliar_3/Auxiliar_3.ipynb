{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auxiliar 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLLTxJRSwscP",
        "colab_type": "text"
      },
      "source": [
        "# Parte 1, Introducción\n",
        "\n",
        "<!-- Tomar en consideracion que los chicos no han visto nada practico en deep learning. No se les explicaron cosas como optimizers, schedulers, etc asique hay que ser pedagogicos.\n",
        "\n",
        "* Motivacion, trabajo con tensores, dimensionalidad alta, optimizacion en gpu, utilidad de computo por batch (eficiencia, robustez del modelo, etc)\n",
        " \n",
        "\n",
        "* introducir la api, las operaciones basicas, operaciones de creacion, operaciones inplace, cambiar la forma de los tensores, etc\n",
        "\n",
        "* mostrar el uso de la gpu con ejemplos (mostrar nvidia-smi), revisar codigo agnostico al dispositivo -->\n",
        "\n",
        "\n",
        "------------------------------------------------------\n",
        "En esta auxiliar vamos a introducir pytorch, un framework para hacer deep learning, y también mostrar dos aplicaciones. Esta herramienta va a ser usada de aquí hasta el final del curso, así que es importante que tengan un conocimiento base sobre este framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2EvTlRNbfSV",
        "colab_type": "text"
      },
      "source": [
        "## Me tinca, pero que es PyTorch exactamente?\n",
        "\n",
        "Como les decia, PyTorch es un framework para hacer deep learning. Las caracteristicas principales de un framework de este tipo es que permite trabajar y realizar operaciones basicas con tensores (abajo explicamos que son y por qué nos interesan), permite usar facilmente y de forma transparente la GPU, si es que existe (mas delante explicamos por que querriamos hacer esto)  y tambien viene con varias utilidades ya implementadas para acelerar el desarrollo de redes neuronales. Por ejemplo, viene con varios modulos de redes neuronales, como capas lineales (como las que vieron en clases), capas recurrentes, capas convulocionales (estas se ven mas adelante), funciones de activacion, funciones de perdida, etc. Finalmente, y quiza lo mas importante del framework, es que viene con un motor de diferenciacion y propagacion de gradientes automatico, es decir, se guarda un registro de las operaciones que se realizan sobre un tensor y luego se puede calcular automaticamente la derivada de un tensor de salida con respecto a los parametros que estuvieron involucrados en su calculo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woZQw3j2bkPw",
        "colab_type": "text"
      },
      "source": [
        "## Ya si, pero tranquilo, qué es un tensor?\n",
        "\n",
        "Un tensor es una estructura matemática para organizar datos. De toda la vida hemos sabido lo que es un \"número\", en física y álgebra lineal vimos que podemos organizar varios números en una lista ordenada para obtener un \"vector\", y luego vimos que podíamos organizar más números en una estructura bidimensional, una \"matriz\", con filas y columnas.\n",
        "\n",
        "Los tensores son una forma de generalizar esta idea, entonces decimos que un numero wacho es un tensor de 0 dimensiones, un vector es un tensor de 1 dimensión y una matriz es un tensor de 2 dimensiones. Este concepto nos permite generalizar esta forma de organizar los datos a dimensiones mayores. Podemos hablar de un \"cubo\" (un tensor de 3 dimensiones), que se podría interpretar como varias matrices apiladas, o más generalmente un tensor de N dimensiones donde N es un número cualquiera (entre mas grande N mas difícil de imaginar :D). Los tensores de dimensiones mayores se los pueden imaginar como listas, donde sus elementos son tensores de dimensiones menores. Esto lo pueden ver en la siguiente fotaza:\n",
        "\n",
        "(source: knoldus)\n",
        "\n",
        "![visualizacion tensor](https://i.stack.imgur.com/Lv1qU.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-CrbVL5bsrm",
        "colab_type": "text"
      },
      "source": [
        "## Buena, me queda claro qué son, ahora por qué me interesan?\n",
        "\n",
        "Cuando uno trabaja en deep learning, es muy común encontrarse con datos de alta dimensionalidad. En NLP por ejemplo, en el capitulo de embeddings vimos que es útil representar una palabra como un vector que captura información de la palabra, ya sea de su contexto, de los caracteres que contiene, etc. Tomando esto en cuenta, vemos que una lista de palabras (una frase) la podemos representar como una matriz. A estas alturas ya tenemos un tensor de 2 dimensiones, pero ¿qué pasa si por alguna razón queremos operar sobre varias frases a la vez? ¿Qué pasa si tenemos una lista de frases? Bueno, ahora tenemos un \"cubo\", un tensor de 3 dimensiones, donde la primera dimensiones corresponde a cada frase dentro del conjunto, la segunda a cada palabra dentro de la frase y finalmente la tercera a cada una las posiciones dentro del vector de embeddings. Esto se repite en muchas más áreas, por ejemplo una imagen RGB es un tensor de 3 dimensiones, un video, donde hay una lista de imágenes se puede interpretar como un tensor de 4 dimensiones, y así.\n",
        "\n",
        "\n",
        "Otra razón por la que el manejo de tensores se vuelve importante es el concepto de _mini-batch_, donde varios ejemplos se procesan a la vez, efectivamente aumentando en uno la dimensión de los tensores usados para los ejemplos.\n",
        "\n",
        "En clases se vio que la forma en la que se entrenan las redes neuronales es un proceso iterativo, donde en primer lugar se realiza una predicción que es mala, se calcula una función de perdida, para cada parámetro se calcula el gradiente de la _loss_ con respecto a este parámetro y luego se desciende en la dirección de este gradiente para tratar de llevar los parámetros a los valores que minimizan la función de perdida. Si este proceso iterativo se llevara a cabo de a un ejemplo a la vez, el valor de la _loss_ sería muy dependiente del ejemplo concreto que se acaba de observar y podría no ser representativo de la _loss_ general. Esto resulta en actualizaciones ruidosas de los parámetros, porque la _loss_ para el siguiente ejemplo puede ser muy distinta al valor anterior y así es como los parámetros pueden oscilar y tener dificultad para converger.\n",
        "\n",
        "Acá es donde nos viene a rescatar el concepto de _mini-batch_, donde los ejemplos se pasan por la red en grupos pequeños para que cada conjunto produzca una  _loss_ más representativa. Esto le agrega robustez al modelo y lo ayuda a converger. El tamaño del _mini-batch_ (cantidad de ejemplos que se pasan a la vez) se vuelve un hiper parámetro de la red. Los valores óptimos de tamaño de _mini-batch_ pueden variar mucho, pero los números que yo he visto varían entre 8 y 32, aunque para algunas aplicaciones he visto valores del orden de 1000.\n",
        "\n",
        "\n",
        "Pueden leer un poco más [acá](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/), la sección introductoria lo explica un poco en más detalle, y cita al libro [Deep Learning](https://www.deeplearningbook.org/), que es muy weno :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCm5gsibx5s",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Oye, pero esto esta medio enredado, te podrías sacar unos ejemplos?\n",
        "La API realmente es muy similar a la de Numpy, asique veremos unos pocos ejemplos nomás. La documentación sobre los tensores la pueden pillar [acá](https://pytorch.org/docs/stable/tensors.html) y la documentacion general de la operaciones sobre tensores que ofrece pytorch esta [acá](https://pytorch.org/docs/stable/torch.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsaS37KAzZoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install torch # en sus maquinas\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhqLuYsIYTtt",
        "colab_type": "code",
        "outputId": "ac1b26b1-0bb4-4c90-d251-c6e9211e988c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Creacion a partir de otra estructura\n",
        "a = [[2,3,4], [4,5,6]]\n",
        "t = torch.tensor(a)\n",
        "print(\"Desde una lista de listas\\n\", t)\n",
        "print(\"\\nDimensiones del tensor\\n\", t.size())\n",
        "print(\"\\nNumero de dimensiones del tensor\\n\", t.dim())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Desde una lista de listas\n",
            " tensor([[2, 3, 4],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Dimensiones del tensor\n",
            " torch.Size([2, 3])\n",
            "\n",
            "Numero de dimensiones del tensor\n",
            " 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbmxaTNpeeCI",
        "colab_type": "code",
        "outputId": "4d81077f-b936-4ada-c387-d3635e6b3d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Creacion de un tensor \"vacio\"\n",
        "t = torch.empty(2,3)\n",
        "print(\"Tensor vacio\\n\", t)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor vacio\n",
            " tensor([[1.4515e-36, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 6.4460e-44]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4oh5DZJehaF",
        "colab_type": "code",
        "outputId": "9a8a81d3-467c-42e1-eb78-ede50be7ca28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Creacion de tensores con puros 1 o puros ceros\n",
        "t = torch.ones(2,3,4)\n",
        "# t = torch.zeros(2,3,4,5)\n",
        "print(\"Puros unos\\n\", t) # notar la tercera dimension"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puros unos\n",
            " tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PLHgzdMe2cb",
        "colab_type": "code",
        "outputId": "a11c04d8-c0ed-471f-93c2-759b3871ded6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Random sampling\n",
        "t = torch.empty(3, 2).uniform_() # notar operacion in-place\n",
        "print(\"Distribucion uniforme\\n\", t)\n",
        "\n",
        "t = torch.randn(2, 3)\n",
        "print(\"\\nDistribucion normal\\n\", t)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribucion uniforme\n",
            " tensor([[0.9071, 0.9928],\n",
            "        [0.3650, 0.6511],\n",
            "        [0.3911, 0.0297]])\n",
            "\n",
            "Distribucion normal\n",
            " tensor([[-1.1560, -0.8267, -1.9774],\n",
            "        [-0.9214,  1.8734,  1.1492]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33AQwoOXobdD",
        "colab_type": "code",
        "outputId": "676d993d-c08f-41c6-bc24-f44f3497a0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Operaciones matematicas\n",
        "t = torch.ones(3,4)\n",
        "print(\"Operaciones con escalares\\n\", t + 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operaciones con escalares\n",
            " tensor([[6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBINbVumph2W",
        "colab_type": "code",
        "outputId": "293a8863-3a2a-4aff-8d3e-aeee988ac7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Operaciones entre tensores\n",
        "t1 = torch.ones(2, 3)\n",
        "t2 = torch.ones(2, 3) * 2\n",
        "print(\"Operaciones entre tensores\\n\", t1 + t2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operaciones entre tensores\n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ouTAQYXxyH",
        "colab_type": "code",
        "outputId": "fb8fdfb1-0fb1-4455-8408-f37b71bf672b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Tambien se pueden hacer operaciones in-place, se modifica el mismo tensor\n",
        "t = torch.ones(2,3)\n",
        "t.add_(1)\n",
        "print(\"Suma in-place\\n\", t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Suma in-place\n",
            " tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N33ZYc3LYH94",
        "colab_type": "code",
        "outputId": "75aba5fe-af28-4034-e165-c31a62aa02c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# Hay veces que es util reorganizar los datos de un tensor, o agregar\n",
        "# dimensiones \n",
        "\n",
        "t = torch.arange(16)\n",
        "print(\"Dimensiones de partida\\n\", t.shape)\n",
        "\n",
        "t = t.view(-1, 8)\n",
        "print(\"\\nUsamos el metodo .view() y el -1 para que torch infiera dimensiones\\n\", t.shape)\n",
        "\n",
        "t = t.flatten() # Aqui tambien se podria usar .view(-1)\n",
        "print(\"\\nPodemos volver a aplanar el tensor con .flatten()\\n\", t.shape)\n",
        "\n",
        "t = t.view(-1, 4).unsqueeze(1) # tambien podria ser .view(-1, 1, 4)\n",
        "print(\"\\nPodemos agregar dimensiones sin agregar datos con .unsqueeze()\\n\", t.shape)\n",
        "\n",
        "t = t.squeeze()\n",
        "print(\"\\nCon .squeeze() podemos sacar todas las dimensiones de tamanno 1\\n\", t.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensiones de partida\n",
            " torch.Size([16])\n",
            "\n",
            "Usamos el metodo .view() y el -1 para que torch infiera dimensiones\n",
            " torch.Size([2, 8])\n",
            "\n",
            "Podemos volver a aplanar el tensor con .flatten()\n",
            " torch.Size([16])\n",
            "\n",
            "Podemos agregar dimensiones sin agregar datos con .unsqueeze()\n",
            " torch.Size([4, 1, 4])\n",
            "\n",
            "Con .squeeze() podemos sacar todas las dimensiones de tamanno 1\n",
            " torch.Size([4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noj-NgUarIXt",
        "colab_type": "text"
      },
      "source": [
        "## Pocazos ejemplos... ya pero en honor al tiempo, ¿qué era eso que decías de la GPU?\n",
        "\n",
        "La GPU es la tarjeta de video de los computadores, un chip que esta especialmente diseñado para manipular muchas matrices de píxeles y aplicarles transformaciones (recuerden que un arreglo de matrices es un tensor de 3 dimensiones), para que luego esos píxeles sean enviados a la pantalla para que los podamos ver. La mayoría de las operaciones tensoriales se pueden paralelizar, por lo que la GPU se aprovecha de esta propiedad y es capaz de realizar operaciones sobre una matriz completa en un solo ciclo de reloj (muy muy rápido). Esto puede mejorar el tiempo de computación hasta por un factor de 100 en cierto casos.\n",
        "\n",
        "Es por esto que las GPUs se usan tanto en deep learning, porque el deep learning esta basado en operaciones básicas sobre tensores, pero en cantidades enormes. Nos estamos aprovechando de años de investigación y desarrollo de chips para que los gamers puedan tener juegos más fluidos, y les estamos dando un uso ~~productivo~~ científico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3in0Nv1fZ9N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Me estas diciendo que hay un componente de en mi PC que me sirve para jugar Minecraft y además para hacer investigacion??!! ¿Cómo lo uso?\n",
        "\n",
        "Otra de las gracias de PyTorch es que permite de forma muy transparente para el usuario interactuar con la GPU. Mover tensores desde la CPU (que es donde se crean por default) hacia la GPU se hace en una pura línea, y además es muy simple escribir código \"agnóstico\" al dispositivo, lo que significa que si el sistema donde se corre el código dispone de GPUs estas se ocupan, pero si no, se ocupa la CPU nomás.\n",
        "\n",
        "A continuación hay unos ejemplos, y pueden leer más al respecto [acá](https://pytorch.org/docs/stable/notes/cuda.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8EjrIZnypw5",
        "colab_type": "code",
        "outputId": "4e46e918-6cf1-4805-b4fa-9cbe2da42b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Primero usemos un comando de shell para obtener informacion de la GPU\n",
        "# Recuerden cambiar el runtime del colab\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  9 18:54:50 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgAok3BJzSWi",
        "colab_type": "code",
        "outputId": "0398af1e-9493-43c7-a48b-1d15310729df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Verificar si cuda esta disponible en el entorno\n",
        "print(\"Habemus GPU?\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available(): # Usar esto para codigo agnostico\n",
        "    print(\"Cuantas GPUs me regala Google?\", torch.cuda.device_count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Habemus GPU? True\n",
            "Cuantas GPUs me regala Google? 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1cyvw3mzeMP",
        "colab_type": "code",
        "outputId": "41fc8fd1-b316-4ae4-e328-8199d8114c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Mover tensores entre gpu y cpu\n",
        "t = torch.empty(3, 4)\n",
        "print(f\"Los tensores se instancian en la {t.device} por default\")\n",
        "\n",
        "t = t.cuda() # .cuda() retorna un nuevo tensor en GPU\n",
        "print(f\"Pero se pueden mover al dispositivo {t.device} usando el methodo .cuda()\")\n",
        "\n",
        "t = torch.empty(3, 4).to(\"cuda\") # Tambien se puede usar con \"cpu\"\n",
        "print(f\"Tambien se pueden llevar a {t.device} usando el metodo .to()\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los tensores se instancian en la cpu por default\n",
            "Pero se pueden mover al dispositivo cuda:0 usando el methodo .cuda()\n",
            "Tambien se pueden llevar a cuda:0 usando el metodo .to()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeYMoyGFv9zO",
        "colab_type": "code",
        "outputId": "ad089c7c-0028-44f5-88a4-5e30cab9a2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Veamos el uso de la gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  9 18:56:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    31W /  70W |    787MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IisFuXt1Bqi",
        "colab_type": "code",
        "outputId": "fe5e1d81-0038-476d-a3e7-2870b940d565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Ahora creemos un tensor tremendo\n",
        "t = torch.empty(6000, 1000, 1000, device=\"cuda\", dtype=torch.int8) # Cada elemento pesa 1 byte\n",
        "\n",
        "# Y veamos cuanta VRAM estamos usando\n",
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  9 18:57:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P0    31W /  70W |   6511MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi57aSyh12CV",
        "colab_type": "text"
      },
      "source": [
        "## Oye pero mi GPU no es tan bacán, no tengo tanta VRAM, me voy a echar el ramo u.u\n",
        "\n",
        "Pucha, las GPUs son caras, pero por suerte San Google se baña en dinero y nos regala tiempo de GPU en Colab.\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "    Google \\downarrow\n",
        "\\end{equation}\n",
        "\n",
        "<center><img src=\"https://media.giphy.com/media/Xy2PrQq6BIw7u/giphy.gif\"></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0RaV-s4kx_",
        "colab_type": "text"
      },
      "source": [
        "## Oye, a mi no me gusta derivar, que era eso de que PyTorch deriva automáticamente?\n",
        "\n",
        "Otra gracia mas de PyTorch (un framework muy agraciado) es que puede almacenar el grafo de computación luego de realizar operaciones sobre tensores. Esto, sumado al hecho que por detrás todas las funciones que usa el framework tienen su respectivas derivadas implementadas, permite que se pueda calcular la derivada de un nodo raíz del grafo de computación (tensores de salida) con respecto una hoja (tensores de entrada). Más información con respecto a autograd se puede obetener [acá](https://pytorch.org/docs/stable/notes/autograd.html).\n",
        "\n",
        "\n",
        "\n",
        "Veamos un ejemplo super simple (como no me quiero complicar la vida, son puras operaciones punto a punto)\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "out & = mean(x^2 + log(x)) \\\\\n",
        "\\frac{\\partial out}{\\partial x_i} & = \\sum_j \\frac{\\partial mean(y)}{\\partial y_j} \\frac{\\partial (x_j^2 + log(x_j))}{\\partial x_i} \\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Recordar que `out` es un número, mientras que `x` es un tensor. Para este ejemplo voy a suponer que `x` es un tensor de una sola dimensión, pero la explicación aplica también para tensores de más dimensiones.\n",
        "\n",
        "Veamos primero como queda la primera derivada.\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial mean(y)}{\\partial y_j} = \\frac{1}{len(y)}\\frac{y_1 + \\dots + y_j + \\dots + y_n}{\\partial y_j} = \\frac{1}{len(y)}, \\forall j\n",
        "\\end{equation}\n",
        "\n",
        "Si se fijan, el largo de un vector no depende de ningún valor específico, y como el promedio es una suma de los elementos del tensor, la derivada es $\\frac{1}{len(y)}$.\n",
        "\n",
        "La siguiente derivada es más fácil, ya que son solo operaciones punto a punto. Todas las posiciones que no dependen de la posición _i-esima_ se van a cero. La derivada queda como sigue.\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\frac{\\partial (x_j^2 + log(x_j))}{\\partial x_i} & = \n",
        "\\begin{cases}\n",
        "2x_i + \\frac{1}{x_i} & \\text{ if } j = i \\\\ \n",
        "0 & \\text{ if } j \\neq i\n",
        "\\end{cases} \\\\\n",
        "\\sum_j \\frac{\\partial (x_j^2 + log(x_j))}{\\partial x_i} & = 2x_i + \\frac{1}{x_i}\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Con estas dos derivadas calculadas podemos volver a la ecuación incial y calcular el valor total de la derivada original. Queda de la siguiente forma (más un poco de algebra para que la ecuación quede bonita).\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial out}{\\partial x_i} = \\frac{2x_i^2 + 1}{x_ilen(x)}\n",
        "\\end{equation}\n",
        "\n",
        "Si probamos con el vector $x=[1,2,3,4]$, reemplazando en la formula deberíamos obtener que el gradiente con respecto a $x$ es $[\\frac{3}{4},\\frac{9}{8},\\frac{19}{12},\\frac{33}{16}] = [0.75, 1.125, 1.5833, 2.0625]$\n",
        "\n",
        "Ahora veamos como pytorch lo hace todo automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxDqe1fn4juH",
        "colab_type": "code",
        "outputId": "d0c518b7-518b-42c1-a2ad-ca853990cf03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = torch.arange(1., 5., requires_grad=True) # Se registra en el grafo de computacion\n",
        "out = torch.mean(x**2 + torch.log(x))\n",
        "out.backward() # Se usa backpropagation para calcular gradientes\n",
        "\n",
        "print(\"Gradiente de out con respecto a x\\n\", x.grad)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradiente de out con respecto a x\n",
            " tensor([0.7500, 1.1250, 1.5833, 2.0625])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCldodKYqVVV",
        "colab_type": "text"
      },
      "source": [
        "## Ohh que cosa mas bacán\n",
        "\n",
        "Una última cosa, la api de PyTorch es gigante así que yo recomiendo que cuando quieran realizar alguna operación sobre un tensor y no pillen fácilmente en la documentación una forma directa de hacerlo, nos pregunten nomás. Preguntas del tipo: \"como hago x en pytorch\" o \"como hago y en pytorch\" son perfectamente razonables, no tengan verguenza de preguntar en el foro :D\n",
        "\n",
        "\n",
        "Hasta acá llega la introducción a PyTorch, cualquier duda extra nos pueden preguntar extensivamente en el foro o por el grupo de telegram.\n",
        "\n",
        "\n",
        "_Eso es todo amigos_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AOSmuAsmA8",
        "colab_type": "code",
        "outputId": "37ed452f-7daa-4304-b7ec-86243cd1eb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "%%html\n",
        "<iframe \n",
        "    width=\"560\"\n",
        "    height=\"315\"\n",
        "    src=\"https://www.youtube.com/embed/Ga_RwPmx-N0\"\n",
        "    frameborder=\"0\"\n",
        "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
        "    allowfullscreen>\n",
        "</iframe>"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe \n",
              "    width=\"560\"\n",
              "    height=\"315\"\n",
              "    src=\"https://www.youtube.com/embed/Ga_RwPmx-N0\"\n",
              "    frameborder=\"0\"\n",
              "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
              "    allowfullscreen>\n",
              "</iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z17VgtH0xiz-",
        "colab_type": "text"
      },
      "source": [
        "# Parte 2: BOW + Logistic Regression \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z3WpurA4hIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8WUqQM0_i7z",
        "colab_type": "text"
      },
      "source": [
        "Cargamos el dataset para las partes que siguen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWlsv6O-_ipp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('constitucion_train80.csv', sep=',')\n",
        "test_data = pd.read_csv('constitucion_test20.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLw8zoni2Yub",
        "colab_type": "text"
      },
      "source": [
        "Veamos primero que es lo que tiene el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jjS6LYw2bvL",
        "colab_type": "code",
        "outputId": "fe0de704-7817-4cf9-93de-da5090318bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>argument</th>\n",
              "      <th>constitutional_concept</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>básica, permite ser, existir. comprende derech...</td>\n",
              "      <td>A la vida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aceptación de diversas tendencias y opiniones.</td>\n",
              "      <td>Tolerancia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-</td>\n",
              "      <td>De protección y conservación de patrimonio his...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>inculcar la inclusión de todos los sectores de...</td>\n",
              "      <td>Inclusión</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nuestro deber como ciudadano es cumplir con es...</td>\n",
              "      <td>Cumplimiento de obligaciones fiscales</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            argument                             constitutional_concept\n",
              "0  básica, permite ser, existir. comprende derech...                                          A la vida\n",
              "1     aceptación de diversas tendencias y opiniones.                                         Tolerancia\n",
              "2                                                  -  De protección y conservación de patrimonio his...\n",
              "3  inculcar la inclusión de todos los sectores de...                                          Inclusión\n",
              "4  nuestro deber como ciudadano es cumplir con es...              Cumplimiento de obligaciones fiscales"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze5M-JIGHwKw",
        "colab_type": "text"
      },
      "source": [
        "Creamos el vocabulario que necesitamos para generar el modelo de Bag of Words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jri00EMPHZ_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "palabras = {}\n",
        "for sent in [x.split() for x in (list(train_data['argument'])+list(test_data['argument']))]:\n",
        "    for word in sent:\n",
        "        if word not in palabras:\n",
        "            palabras[word] = len(palabras)\n",
        "\n",
        "\n",
        "VOCAB_SIZE = len(palabras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CudXRXGJ9DK",
        "colab_type": "text"
      },
      "source": [
        "Cuantos labels vamos a clasificar?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55i8v31bKCX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_to_idx = {}\n",
        "for label in set(list(train_data['constitutional_concept'])+list(test_data['constitutional_concept'])): # Utilizamos 'set' para obtener los valores únicos\n",
        "      if label not in labels_to_idx:\n",
        "          labels_to_idx[label] = len(labels_to_idx)\n",
        "\n",
        "NUM_LABELS = len(labels_to_idx) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzkpJjNoK1p0",
        "colab_type": "code",
        "outputId": "a53bb3df-0791-4823-e7ae-e9897fbb6cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(VOCAB_SIZE)\n",
        "print(NUM_LABELS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48318\n",
            "161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9kGvoy4H96w",
        "colab_type": "text"
      },
      "source": [
        "Tenemos entonces un vocabulario de 70401 palabras y queremos clasificar entre 160 tópicos distintos.\n",
        "\n",
        "Las siguientes funciones auxiliares nos permiten obtener las representaciones BoW."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoI174XnSEsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_bow_vector(batch): # Representacion en bag of words (sentence es una lista de las palabras)\n",
        "    ret = []\n",
        "    for sentence in batch:\n",
        "        vec = torch.zeros(VOCAB_SIZE)\n",
        "        for word in sentence.split():\n",
        "            vec[palabras[word]] += 1 # Le sumamos 1 a la columna que representa la palabra\n",
        "        ret.append(vec.view(1, -1))\n",
        "    return tuple(ret)\n",
        "\n",
        "\n",
        "def make_target(batch): # Tensor que contiene one hot spot del label.\n",
        "    ret = []\n",
        "    for label in batch:\n",
        "        ret.append(torch.LongTensor([labels_to_idx[label]]))\n",
        "    return tuple(ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADHbfLnnSUK_",
        "colab_type": "text"
      },
      "source": [
        "Generamos un \"Dataloader\" para los datos de training. Este dataloader nos permite separar los datos en mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpUGjGXd2uIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_train_data = []\n",
        "for index, row in train_data.iterrows(): # Iteramos en el df de pandas de entrenamiento\n",
        "    bow_train_data.append((row['argument'],row['constitutional_concept']))\n",
        "trainloader = torch.utils.data.DataLoader(bow_train_data, batch_size=16,\n",
        "                                          shuffle=True, num_workers=10)\n",
        "dataiter = iter(trainloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Z7AtuF29Ql",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver que nos entrega una iteracion del dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyZC-HseSTZ2",
        "colab_type": "code",
        "outputId": "eaf559a3-f7b5-4b59-da72-3f3002dd695e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "argument, concept = dataiter.next()\n",
        "print(argument)\n",
        "print(concept)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('asegurar que nuestros derechos sean respetados y considerados', 'es el deber mínimo de todo ciudadano.', 'asegurar la prolijidad en todos los aspectos del estado.', 'más descentralización y poder político y económico a las regiones.', 'conservar historia y patrimonio arquitectónico, las expresiones culturales, monumentos históricos y patrimonio arqueológicoconservar y respetar culturas y lenguas extintas y las vivas.fundamental para tener una nación con identidad o identidades para crear un sentido de pertenencia.', 'todos los ciudadanos deberían ser iguales ante la ley sin importar sus diferencias.', 'en base a la situación actual que vive el país se hace necesario un mejoramiento en los mecanismos de fiscalización.', 'para superar el manejo o manipulaciòn de la opinión publica donde se esconden datos, se habla mal de algunas fuerzas polìticas, sin darles oportunidad de que ellos den su propia versiòn.', 'la constitucion debe contemplar como se estructura el gobierno las fucniones que debe cumplir y sus atribuciones.', 'masificar el quehacer ciudadano.', 'hoy estan vulnerados nuestreos derechos, son sobrellevados por ejemplo: la proteccion de los niños no exsite que por el hecho de ser pobres se los quitan a la familia.', 'subordinadas a las autoridades del estado elegidas por la ciudadanía, erradicando toda doctrina de confrontación o represión contra el pueblo ej. doctrina de seguridad nacional. se rigen por justicia civil, formación depende de un currículum nacional y abierto. los recursos destinados se disminuy', 'protección permanente en los derechos humanos y la policía y fuerzas armadas deben estar capacitados en este ámbito y cumplirla.', 'porque es la sinvergüenzura más grande cotra los trabajadores', 'el estado debe establecer un mecanismo impositivo justo sobre todos los entes que tributan, sean estos personas jurídicas o naturales. es deber de las personas tomar conciencia de que forman parte de un sistema y que hay que cumplir con esos requerimientos para su buen funcionamiento.', 'fomentar la solidaridad para cambiar la sociedad individualista que provoca un mercado como el actual, para la formación de una sociedad más equitativa en donde desde el más pobre hasta el más rico cooperar según su situación económica')\n",
            "('Protección, promoción y respeto de los derechos humanos y fundamentales', 'De voto o sufragio', 'Juicio político /acusación constitucional', 'Gobierno regional', 'De protección y conservación de patrimonio histórico y cultural', 'Igualdad de acceso a la justicia / Debido proceso', 'Contraloría general / Tribunales de cuentas', 'A la información', 'Gobierno nacional (estructura y funciones)', 'Inclasificable/No corresponde', 'Protección, promoción y respeto de los derechos humanos y fundamentales', 'Fuerzas Armadas', 'Protección, promoción y respeto de los derechos humanos y fundamentales', 'A la seguridad social', 'Cumplimiento de obligaciones fiscales', 'Solidaridad')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afLoEpVa3GU-",
        "colab_type": "text"
      },
      "source": [
        "Generamos también el conjunto de testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOwU14Nc3JPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_test_data = []\n",
        "for index, row in test_data.iterrows(): # Iteramos en el df de pandas de entrenamiento\n",
        "    bow_test_data.append((row['argument'],row['constitutional_concept']))\n",
        "testloader = torch.utils.data.DataLoader(bow_test_data, batch_size=16,\n",
        "                                          shuffle=True, num_workers=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHO4IpOlSjsx",
        "colab_type": "text"
      },
      "source": [
        "Configuramos nuestro clasificador, extendiendo la clase nn.Module de pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4AVUSNzH-Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoWClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, vocab_size):\n",
        "        super(BoWClassifier, self).__init__()  # Primero llamamos al constructor de la superclase.\n",
        "        # Luego le agregamos los parametros necesarios para el modelo, en este caso pasamos de un tensor de largo vocab_size a otro de largo num_labels.\n",
        "        self.linear = nn.Linear(vocab_size, num_labels)\n",
        "\n",
        "    def forward(self, bow_vec):\n",
        "        # Pasamos el input por la capa lineal y terminamos con su vector de labels.\n",
        "        return self.linear(bow_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-rBtgs8Tss7",
        "colab_type": "text"
      },
      "source": [
        "Inicializamos el modelo, entregando que funcion de loss y que optimizador vamos a usar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWndsrkmJiXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE).cuda()\n",
        "loss_function = nn.CrossEntropyLoss() # CrossEntropy calcula el softmax, si no seria necesario agregarla al modelo\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnTEMc5W3pdg",
        "colab_type": "text"
      },
      "source": [
        "Sólo para demostrar que sí se logró entrenar algo, veremos el accuracy pasandolo por el modelo antes de entrenar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqWy3ekE3ub6",
        "colab_type": "code",
        "outputId": "534a8ea4-8a8e-472e-b868-536aba6965f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = 0\n",
        "good = 0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    total += len(inputs)\n",
        "    bow_vec = torch.stack(make_bow_vector(inputs)).cuda()\n",
        "    target = torch.stack(make_target(labels)).cuda()\n",
        "    outputs = model(bow_vec)\n",
        "    equal_classes = (torch.argmax(outputs, dim=2) == target).sum() # Suma todas las clases que son iguales\n",
        "    good += equal_classes.item() # Extraemos el valor del tensor\n",
        "print('Accuracy: {0}'.format(good/total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.006866827379647893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQZt0iI9TuZ2",
        "colab_type": "text"
      },
      "source": [
        "Y el paso mas importante: Entrenar!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvp68O6ETyAY",
        "colab_type": "code",
        "outputId": "9d2232e1-0e2f-49b4-ec21-9b3b4f88f48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "for epoch in range(15):\n",
        "    running_loss = 0.0\n",
        "    t = tqdm(enumerate(trainloader, 0), leave=True) # Barra que muestra progreso\n",
        "    for i, data in t:\n",
        "        inputs, labels = data\n",
        "        model.zero_grad() # Limpiar los gradientes antes de cada iteración\n",
        "\n",
        "        bow_vec = torch.stack(make_bow_vector(inputs)).cuda()\n",
        "        target = torch.stack(make_target(labels)).cuda()\n",
        "        # Hacer un forward pass y ver el resultado\n",
        "        outputs = model(bow_vec)\n",
        "        # Calcular la loss y los gradientes\n",
        "\n",
        "        loss = loss_function(outputs.squeeze(1), target.squeeze(1))\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizar los parametros del modelo\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 0:    # print cada 50 mini-batches\n",
        "            # La loss esta dividida por 50 ya que se fue acumulando durante 50 mini-batches\n",
        "            t.set_description(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss/50)) \n",
        "            t.refresh() # Actualizar la barrita\n",
        "            running_loss = 0.0 # Reseteamos la loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  3501] loss: 174.588: : 3523it [00:23, 150.91it/s]\n",
            "[2,  3501] loss: 158.775: : 3523it [00:24, 146.26it/s]\n",
            "[3,  3501] loss: 144.356: : 3523it [00:24, 146.48it/s]\n",
            "[4,  3501] loss: 136.225: : 3523it [00:23, 149.77it/s]\n",
            "[5,  3501] loss: 126.767: : 3523it [00:23, 151.57it/s]\n",
            "[6,  3501] loss: 120.383: : 3523it [00:23, 152.60it/s]\n",
            "[7,  3501] loss: 123.153: : 3523it [00:23, 152.82it/s]\n",
            "[8,  3501] loss: 116.175: : 3523it [00:22, 153.37it/s]\n",
            "[9,  3501] loss: 113.481: : 3523it [00:23, 151.97it/s]\n",
            "[10,  3501] loss: 111.522: : 3523it [00:23, 152.70it/s]\n",
            "[11,  3501] loss: 103.419: : 3523it [00:23, 151.81it/s]\n",
            "[12,  3501] loss: 96.769: : 3523it [00:22, 153.62it/s]\n",
            "[13,  3501] loss: 101.566: : 3523it [00:23, 151.36it/s]\n",
            "[14,  3501] loss: 105.740: : 3523it [00:23, 152.40it/s]\n",
            "[15,  3501] loss: 104.850: : 3523it [00:23, 152.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1kKzbpsUkMk",
        "colab_type": "text"
      },
      "source": [
        "Accuracy post entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP9H1Bj032Fg",
        "colab_type": "code",
        "outputId": "a1555ab0-44ef-4fad-a812-905ae476c723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = 0\n",
        "good = 0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    total += len(inputs)\n",
        "    bow_vec = torch.stack(make_bow_vector(inputs)).cuda()\n",
        "    target = torch.stack(make_target(labels)).cuda()\n",
        "    outputs = model(bow_vec)\n",
        "    equal_classes = (torch.argmax(outputs, dim=2) == target).sum()\n",
        "    good += equal_classes.item()\n",
        "print('Accuracy: {0}'.format(good/total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4546716341588136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ufhuHHm337n",
        "colab_type": "text"
      },
      "source": [
        "Para ser un problema con 160 clases, esta accuracy no es mala. Un clasificador que tira una clase al azar dentro de las 160 tendría 0.00625 de accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBl79iRz37zk",
        "colab_type": "text"
      },
      "source": [
        "Parametros con los que pueden jugar:\n",
        "- Cantidad de epochs\n",
        "- Batch_size\n",
        "- Learning rate del optimizer\n",
        "- Cambiar la funcion de loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46jrmdTCxmC1",
        "colab_type": "text"
      },
      "source": [
        "# Parte 3, embeddings + feed forward\n",
        "\n",
        "Acá viene otro ejemplo más, esta vez usando una capa de embeddings y una red feed forward. Para este ejemplo me inspire ~~totalmente~~ parcialmente de [este tutorial](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html) de PyTorch.\n",
        "\n",
        "La próxima auxiliar veremos más utilidades de torchtext, vamos a probar usando embeddings preentrenados y vamos a ver ejemplos de otras arquitecturas más complejas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "930w9SpaQoAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture --no-stderr\n",
        "!pip install --upgrade torchtext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afl8sll3QrKi",
        "colab_type": "code",
        "outputId": "7b5a503d-bd74-49bb-e749-3bc2a51330d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "import csv\n",
        "import http.client\n",
        "import gzip\n",
        "\n",
        "from itertools import islice\n",
        "from random import sample\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Primero descarguemos el dataset\n",
        "HOST = \"raw.githubusercontent.com\"\n",
        "URL = \"/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\"\n",
        "\n",
        "# Descargar los datos directamente de github\n",
        "conn = http.client.HTTPSConnection(HOST)\n",
        "conn.request(\"GET\", URL)\n",
        "\n",
        "# Para este ejemplo solo voy a trabajar con documentos de la categoria 1, \"Valores\"\n",
        "dataset = tuple(\n",
        "    # Usemos lowercase para que el vocabulario no quede tan grande\n",
        "    (row[\"constitutional_concept\"], row[\"argument\"].lower())\n",
        "    for row in tqdm(\n",
        "            csv.DictReader(\n",
        "                gzip.open(conn.getresponse(), mode=\"rt\"),\n",
        "                strict=True,\n",
        "                escapechar=\"\\\\\",\n",
        "            )\n",
        "        )\n",
        "    # Usamos solo el primer topico, y hay algunos argumentos vacios\n",
        "    if row[\"topic\"] == \"1\" and row[\"argument\"]\n",
        ")\n",
        "\n",
        "# Mostremos algunos ejemplos\n",
        "for example in sample(dataset, 3):\n",
        "    print(\"\\nEjemplo aleatorio:\\n\", example)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "205357it [00:01, 138145.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Ejemplo aleatorio:\n",
            " ('Bien Común / Comunidad', 'se requiere trabajar en base a intereses colectivos y no privilegiando intereses personales.')\n",
            "\n",
            "Ejemplo aleatorio:\n",
            " ('Seguridad', '-leyes demasiado blandas y flexibles. -formular leyes más duras. -crear cárceles \"reformatorias\".')\n",
            "\n",
            "Ejemplo aleatorio:\n",
            " ('Respeto / Conservación de la naturaleza o medio ambiente', 'para los habitantes de un sector rural es muy importante el cuidado del medio ambiente, va en directo beneficio de la localidad.  cuidado del agua y de los alimentos')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2YbxqHHQvf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture --no-stderr\n",
        "# Ahora armemos un vocabulario, para esto necesitamos un tokenizador,\n",
        "# pero torchtext no viene con un tokenizador para espannol asi que\n",
        "# hay que bajar uno de spacy\n",
        "!python -m spacy download es"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cO0avAqQwPx",
        "colab_type": "code",
        "outputId": "fd185248-b3c1-49c6-aec4-1a7bd38f1a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Ahora si armemos el vocabulario y la lista de labels\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer(\"spacy\", \"es\")\n",
        "vocab = build_vocab_from_iterator(\n",
        "    tokenizer(argument) for _, argument in dataset\n",
        ")\n",
        "labels = list({doc[0] for doc in dataset})\n",
        "label_map = {label: index for index, label in enumerate(labels)}\n",
        "\n",
        "print(\"\\nTamanno del vocabulario:\", len(vocab))\n",
        "print(\"Algunas palabras del vocabulario:\", sample(vocab.itos, 5))\n",
        "print(\"\\nCantidad de labels:\", len(labels))\n",
        "print(\"Algunos labels:\", sample(labels, 3))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53780lines [00:04, 12948.51lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tamanno del vocabulario: 23765\n",
            "Algunas palabras del vocabulario: ['requeridas', 'incansablemente', 'gretuita', 'soberanos', 'apropiarnos']\n",
            "\n",
            "Cantidad de labels: 55\n",
            "Algunos labels: ['Justicia social', 'Dignidad', 'Equidad']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfLyZ24oQydu",
        "colab_type": "code",
        "outputId": "f8391581-14d1-4983-8951-6ef0df028c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Ahora con este vocabulario podemos armar un set de train y uno de validacion\n",
        "import torch\n",
        "from torch.utils.data.dataset import random_split\n",
        "train_len = int(len(dataset) * 0.8)\n",
        "\n",
        "train_dataset, validation_dataset = [\n",
        "    [\n",
        "        (\n",
        "            label_map[item[0]],\n",
        "            torch.tensor([vocab[token] for token in tokenizer(item[1])]),\n",
        "        )\n",
        "        for item in split\n",
        "    ]\n",
        "    for split in random_split(dataset, [train_len, len(dataset) - train_len])\n",
        "]\n",
        "\n",
        "print(\"Algunos ejemplos del dataset:\")\n",
        "for example in sample(train_dataset, 3):\n",
        "    print(example)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Algunos ejemplos del dataset:\n",
            "(16, tensor([ 201,   12,  357,  413, 1845,   35,  185,   21,  590,  812,    2,    5,\n",
            "          32,    4,   38, 3999,    3]))\n",
            "(0, tensor([  50,   45,    4,  208,   10,   52,  113,   33,    7,  261,  558,    3,\n",
            "        1473,    9,   91,   36,   68,  746,    4,    5,   40,   16,  151,    6,\n",
            "         201,    3]))\n",
            "(16, tensor([3085]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx8m9NyQQ3se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pum ahora hagamos la arquitectura\n",
        "# simplecita, un capa de embedding, y luego una red feed forward de \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Red neuronal con una sola capa escondida\n",
        "class ArgumentClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class, hidden_size, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, pad_idx)\n",
        "        self.fc1 = nn.Linear(embed_dim, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_class)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # (B, N, E) -> (B, E)\n",
        "        # La representacion de un documento sera el promedio de los\n",
        "        # embeddings de sus palabras.\n",
        "        z = self.embedding(batch).mean(dim=1)\n",
        "        z = F.relu(self.fc1(z))\n",
        "        z = F.relu(self.fc2(z))\n",
        "        return torch.softmax(z, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogqQ1DxRQ5Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para mas adelante, necesitamos definir una funcion que determine\n",
        "# como convertir un conjunto de items de nuestro dataset en un batch,\n",
        "# recordando que los tensores en pytorch tienen que ser homogeneos\n",
        "\n",
        "# Esta funcion recibe una lista de muestras del dataset y debe retornar\n",
        "# tensores que agrupan estas muestras. Si cada ejemplo de nuestro dataset\n",
        "# contiene 2 elementos y nuestro tamanno de batch es de 16, entonces esta funcion\n",
        "# debe retorna una tupla de 2 tensores, cada uno de dimension 16 x ... \n",
        "from itertools import zip_longest\n",
        "\n",
        "def generate_batch(batch):\n",
        "    return (\n",
        "        # En este caso como los labels son numeros, el tensor es de 1 dimension\n",
        "        # de tamanno batch_size\n",
        "        torch.tensor([item[0] for item in batch]),\n",
        "\n",
        "        # En este caso se retorna un tensor de 2 dimensiones, batch_size x N,\n",
        "        # donde N es mayor largo de los ejemplo en el batch. Aca se realiza\n",
        "        # padding de los ejemplos mas cortos.\n",
        "        torch.tensor(\n",
        "            list(\n",
        "                zip(\n",
        "                    *zip_longest(\n",
        "                        *[item[1] for item in batch], fillvalue=vocab[\"<pad>\"]\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhUydT9FQ66J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ahora creamos funciones para entrenar y validar el modelo\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def train_func(train_dataset):\n",
        "\n",
        "    # Entranamos el modelo\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=generate_batch,\n",
        "    )\n",
        "    for i, (cls, text) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        cls, text = cls.to(device), text.to(device)\n",
        "        output = model(text)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Ajustar el learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(train_dataset), train_acc / len(train_dataset)\n",
        "\n",
        "\n",
        "def test(test_dataset):\n",
        "    test_loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(\n",
        "        test_dataset, batch_size=BATCH_SIZE, collate_fn=generate_batch\n",
        "    )\n",
        "    for cls, text in data:\n",
        "        cls, text = cls.to(device), text.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            loss = criterion(output, cls)\n",
        "            test_loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return test_loss / len(test_dataset), acc / len(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysOVh-dMQ9Us",
        "colab_type": "code",
        "outputId": "01faa629-ea65-40d4-d7c0-cb0bc2b5870a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "# Ahora por fin tenemos todo lo necesario para entrenar el modelo.\n",
        "import time\n",
        "\n",
        "N_EPOCHS = 5\n",
        "LEARN_RATE = 4.0\n",
        "STEP_SIZE = 1\n",
        "BATCH_SIZE = 32\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_SIZE = 200\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ArgumentClassifier(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_class=len(labels),\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    pad_idx=vocab[\"<pad>\"],\n",
        ").to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARN_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, STEP_SIZE)\n",
        "\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test(validation_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs // 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1}\", f\" | time in {mins} minutes, {secs} seconds\",\n",
        "    )\n",
        "    print(\n",
        "        f\"\\tLoss: {train_loss:.4f}(train)\\t|\"\n",
        "        f\"\\tAcc: {train_acc * 100:.1f}%(train)\"\n",
        "    )\n",
        "    print(\n",
        "        f\"\\tLoss: {valid_loss:.4f}(valid)\\t|\"\n",
        "        f\"\\tAcc: {valid_acc * 100:.1f}%(valid)\"\n",
        "    )\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 5 seconds\n",
            "\tLoss: 0.1218(train)\t|\tAcc: 14.7%(train)\n",
            "\tLoss: 0.1208(valid)\t|\tAcc: 18.2%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 5 seconds\n",
            "\tLoss: 0.1203(train)\t|\tAcc: 19.0%(train)\n",
            "\tLoss: 0.1206(valid)\t|\tAcc: 18.9%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 5 seconds\n",
            "\tLoss: 0.1202(train)\t|\tAcc: 19.2%(train)\n",
            "\tLoss: 0.1206(valid)\t|\tAcc: 19.0%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 5 seconds\n",
            "\tLoss: 0.1202(train)\t|\tAcc: 19.2%(train)\n",
            "\tLoss: 0.1206(valid)\t|\tAcc: 19.1%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 5 seconds\n",
            "\tLoss: 0.1202(train)\t|\tAcc: 19.3%(train)\n",
            "\tLoss: 0.1206(valid)\t|\tAcc: 19.1%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}