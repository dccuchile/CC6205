{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Auxiliar4_parte4.ipynb","provenance":[],"authorship_tag":"ABX9TyN8YnLS8/wkMq8IUMXyqi6I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TGCXZQh4PD5G","colab_type":"text"},"source":["# Cómo ganar en la competencia 2\n","\n","---\n","\n","Esta es la parte 4 de la auxiliar, la parte 3 fue hacer un repaso de la arquitectura base propuesta para la competencia 2 y recomendaciones generales sobres los experimentos que pueden hacer para su informe.\n","\n","Acá vamos a usar una librería que es super fácil de usar, llamda `flair`, para ver qué puntajes podemos obtener usando modelos preentrenados. Vamos a usar el set de validación de la competencia 2.\n","\n","**IMPORTANTE 1**: Está demás decir que esto no lo pueden usar para la competencia 2, es decir, no pueden llegar y subir los resultados correctos del set de test y suponer que porque les fue super bien en la compentencia van a tener la mejor nota. Lo importante de la competencia es el informe que entregan con los experimentos que realizaron y sus reflexiones. Si los resultados que tienen en la competencia no se corresponden con los resultados que obtienen sus arquitecturas propuestas... no sé rick.\n","\n","**IMPORTANTE 2**: Esto es menos importante eso sí. Este ejemplito es simplemente para demostrar las capacidades de modelos pre-entrenados y las utilidades que ofrece la libreria `flair`. También es posible entrenar los modelos que la librería tiene disponibles uno mismo, con sus propios datasets, pero según lo que te entendí, no es posible (al menos no salía en el tutorial) implementar modelos propios y usarlos en el framework, es más bien para reentrenar los mismos modelos probando datos distintos. Aunque hay que decir que también se puede jugar con los embeddings para el modelo, pero no implementar un nuevo modelo desde 0. De todas formas, si alguien sabe más de `flair`, cualquier comentario es bienvenido."]},{"cell_type":"code","metadata":{"id":"S7eCZMXiPQXz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593673971358,"user_tz":240,"elapsed":4816,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}}},"source":["# Instalamos flair\n","%%capture --no-stderr\n","!pip install --upgrade flair torchtext"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lie7X7cdPDiB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593673973399,"user_tz":240,"elapsed":6845,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}}},"source":["%%capture\n","!wget -nc https://github.com/dccuchile/CC6205/releases/download/Data/val_NER_esp.txt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEaeLVH5Of7z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593673974611,"user_tz":240,"elapsed":8050,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}}},"source":["# En esta parte simplemente voy a cargar el dataset con torchtext, porque\n","# me parece que no es tan simple cargar un solo split de un dataset con\n","# flair. Como que esta disennado para cargar un dataset completo (un corpus)\n","# con los tres splits al tiro.\n","from torchtext import data, datasets\n","\n","TAG = data.Field(unk_token=None, pad_token=None)\n","TEXT = data.Field()\n","\n","dataset = datasets.SequenceTaggingDataset(\n","    \"val_NER_esp.txt\",\n","    fields=[(\"text\", TEXT), (\"tags\", TAG)],\n","    encoding=\"iso-8859-1\",\n","    separator=\" \",\n",")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNnA6tshVs2p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593673986982,"user_tz":240,"elapsed":20414,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"3b983f55-f7d7-45df-8bc2-7d8ba5ae3749"},"source":["# Aca cargamos un tagger, de tipo ner y entrenado con un corpus multilingual\n","# que incluia espannol\n","from flair.models import SequenceTagger\n","tagger = SequenceTagger.load(\"ner-multi\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2020-07-02 07:11:50,499 loading file /root/.flair/models/quadner-large.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YYs1zEHVbPDJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593673986987,"user_tz":240,"elapsed":20412,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"073bbcfc-6559-414c-bd5b-2bf3276d3316"},"source":["# Printiemos el diccionario de tags del tagger, para ver si son compatibles\n","# con el esquema BIO del dataset.\n","# En este caso usan BIOES, asique vamos a tener que transformar los tags que\n","# produce el tagger mas adelante\n","print(tagger.tag_dictionary.get_items())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['<unk>', 'O', 'B-PER', 'E-PER', 'S-LOC', 'B-MISC', 'I-MISC', 'E-MISC', 'S-PER', 'B-ORG', 'E-ORG', 'S-ORG', 'I-ORG', 'B-LOC', 'E-LOC', 'S-MISC', 'I-PER', 'I-LOC', '<START>', '<STOP>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"goSGzpnaXQ2O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1593673987371,"user_tz":240,"elapsed":20788,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"947af31d-9fb4-4c8c-f97c-ce6ca3d9004c"},"source":["# En esta celda tomamos una frase y la predecimos. Para crear un objeto\n","# `Sentence` en flair hay que pasarle una frase completa en forma de string\n","# y el tokenizador basico que ocupa simplemente hace str.split()\n","# Me parece muy raro que no permita formar frases a partir de tokens\n","# directamente, pero en la investigacion superficial que hice no aparecia como.\n","from pprint import pprint\n","from flair.data import Sentence\n","sentence = Sentence(\" \".join(dataset[5].text))\n","\n","# El tagger modifica la sentence `in-place`, es decir cambia los atributos\n","# del objeto en vez de retornar uno nuevo. Al crear la sentece, los tokens no\n","# tenian asociado un ner-tag y luego de realizar la prediccion si.\n","tagger.predict(sentence)\n","pprint(sentence.to_tagged_string())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["('También participaron en el acto el consejero delegado de Telefónica <B-ORG> '\n"," 'Internacional <E-ORG> , Antonio <B-PER> Viana <I-PER> Baptista <E-PER> ; el '\n"," 'ministro de Comunicaciones <S-MISC> de Brasil <S-LOC> , Joao <B-PER> '\n"," 'Pimienta <I-PER> da <I-PER> Veiga <E-PER> ; el presidente de la ANATEL '\n"," '<S-ORG> , Renato <B-PER> Navarro <I-PER> Guerreiro <E-PER> , y el secretario '\n"," 'de Ciencia. <B-MISC> Tecnología <I-MISC> del <I-MISC> Estado <I-MISC> de '\n"," '<I-MISC> Sao <I-MISC> Paulo <E-MISC> , José <B-PER> Aníbal <I-PER> Peres '\n"," '<I-PER> de <I-PER> Pontes <E-PER> .')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"onCTXavAsjlx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1593673987374,"user_tz":240,"elapsed":20782,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"8320ac44-0f70-4471-e6a2-270b2bc35cbe"},"source":["# La sentence esta compuesta de tokens, y cada token tiene informacion de sus\n","# tags. Aca se muestran los primeros 5 tokens\n","pprint([token for token in sentence[:5]])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[Token: 1 También,\n"," Token: 2 participaron,\n"," Token: 3 en,\n"," Token: 4 el,\n"," Token: 5 acto]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wha5HjfEQ_4M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1593673987375,"user_tz":240,"elapsed":20774,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"44a34ca2-6642-49e4-f74f-a1fd54d7e098"},"source":["# Despues de realizar la prediccion, cada token tiene asociado un tag y\n","# nivel de confianza en el tag asignado.\n","\n","# El modelo esta muy seguro que la palabra \"Tambien\" no es una entidad\n","print(sentence[0], \"\\n\", sentence[0].get_tag(\"ner\"), \"\\n\")\n","# El modelo esta bastante seguro que la palabra \"Telefonica\" es el comienzo\n","# de una organizacion\n","print(sentence[9], \"\\n\", sentence[9].get_tag(\"ner\"))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Token: 1 También \n"," O (1.0) \n","\n","Token: 10 Telefónica \n"," B-ORG (0.8297)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LSR-yCOPR7lP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593673987378,"user_tz":240,"elapsed":20769,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"8ecaeaf9-93da-4f9d-dc88-065c874235b9"},"source":["# Tambien podemos ver que a los tokens de la sentence no se les ha asigando\n","# un tag `pos` todavia. (Noten que no sale nada antes del 1.0)\n","print(sentence[0].get_tag(\"pos\"))"],"execution_count":9,"outputs":[{"output_type":"stream","text":[" (1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pBND4EO1fNxs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593674013887,"user_tz":240,"elapsed":47269,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"b099d1de-8054-4edd-e626-c7ed0170211d"},"source":["# Al tagger igual se le pueden pasar varias sentences para que las taguee,\n","# asi que le vamos a pasar todo el dataset para ver como le va\n","import torch\n","if not torch.cuda.is_available():\n","    raise Exception(\"Cambia el runtime si no quieres estar una tarde en esta celda\")\n","\n","sentences = [Sentence(\" \".join(example.text)) for example in dataset]\n","tagger.predict(sentences, mini_batch_size=128, verbose=True)\n","pass # para que no printee el objeto que retorna el statement anterior"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Inferencing on batch 14: 100%|██████████| 15/15 [00:26<00:00,  1.75s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_e3wDU3gj0z3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593674013891,"user_tz":240,"elapsed":47264,"user":{"displayName":"Gabriel Chaperon","photoUrl":"","userId":"04620641081898711799"}},"outputId":"537e14f4-245a-41dd-85cb-7d4df9c0d6b3"},"source":["# Ahora realizamos la evaluacion, usando el f1_score de entidad predicha\n","# a nivel de token\n","from sklearn.metrics import f1_score\n","\n","# Un mapping para convertir de BIOES a BIO\n","mapping = (\n","    (\"E\", \"I\"),\n","    (\"S\", \"B\")\n",")\n","\n","# Una funcioncita para convertir de BIOES a BIO\n","def to_bio(tag):    \n","    for t_in, t_out in mapping:\n","        tag = tag.replace(t_in, t_out, 1)\n","    return tag\n","\n","\n","TAG.build_vocab(dataset)\n","y_true = [tag for example in dataset for tag in example.tags]\n","y_pred = [to_bio(token.get_tag(\"ner\").value) for sentence in sentences for token in sentence]\n","\n","print(\"El f1_score del set de validacion, asi sin hacer nada, es:\")\n","print(f1_score(y_true, y_pred, labels=[tag for tag in TAG.vocab.itos if tag != \"O\"], average=\"micro\"))\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["El f1_score del set de validacion, asi sin hacer nada, es:\n","0.8137920274592402\n"],"name":"stdout"}]}]}